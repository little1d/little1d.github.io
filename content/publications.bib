@article{shen2025molspectllmmolecularfoundationmodel,
  title    = {MolSpectLLM: A Molecular Foundation Model Bridging Spectroscopy, Molecule Elucidation, and 3D Structure Generation},
  author   = {Shuaike Shen# and Jiaqing Xie# and Zhuo Yang and Antong Zhang and Shuzhou Sun and Ben Gao and Tianfan Fu and Biqing Qi and Yuqiang Li*},
  year     = {2025},
  month    = {sep},
  url      = {https://arxiv.org/abs/2509.21861},
  langid   = {english},
  preview  = {MolSpectLLM.png},
  code     = {https://github.com/Eurekashen/MolSpectLLM},
  abstract = {Recent advances in molecular foundation models have shown impressive performance in molecular property prediction and de novo molecular design, with promising applications in areas such as drug discovery and reaction prediction. Nevertheless, most existing approaches rely exclusively on SMILES representations and overlook both experimental spectra and 3D structural information-two indispensable sources for capturing molecular behavior in real-world scenarios. This limitation reduces their effectiveness in tasks where stereochemistry, spatial conformation, and experimental validation are critical. To overcome these challenges, we propose MolSpectLLM, a molecular foundation model pretrained on Qwen2.5-7B that unifies experimental spectroscopy with molecular 3D structure. By explicitly modeling molecular spectra, MolSpectLLM achieves state-of-the-art performance on spectrum-related tasks, with an average accuracy of 0.53 across NMR, IR, and MS benchmarks. MolSpectLLM also shows strong performance on the spectra analysis task, obtaining 15.5% sequence accuracy and 41.7% token accuracy on Spectra-to-SMILES, substantially outperforming large general-purpose LLMs. More importantly, MolSpectLLM not only achieves strong performance on molecular elucidation tasks, but also generates accurate 3D molecular structures directly from SMILES or spectral inputs, bridging spectral analysis, molecular elucidation, and molecular design.},
  keywords = {Molecular Foundation Model, Spectroscopy, Molecule Elucidation, 3D Structure Generation}
}

@article{yang2025spectrumworldartificialintelligencefoundation,
  selected = {true},
  title    = {SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy},
  author   = {Zhuo Yang# and Jiaqing Xie# and Shuaike Shen and Daolang Wang and Yeyun Chen and Ben Gao and Shuzhou Sun and Biqing Qi and Dongzhan Zhou and Lei Bai and Linjiang Chen and Shufei Zhang and Qinying Gu and Jun Jiang and Tianfan Fu and Yuqiang Li*},
  year     = {2025},
  month    = {aug},
  url      = {https://arxiv.org/abs/2508.01188},
  preview  = {SpectrumWorld.png},
  code     = {https://github.com/little1d/SpectrumLab},
  datasets = {https://huggingface.co/SpectrumWorld},
  langid   = {english},
  abstract = {Deep learning holds immense promise for spectroscopy, yet research and evaluation in this emerging field often lack standardized formulations. To address this issue, we introduce SpectrumLab, a pioneering unified platform designed to systematize and accelerate deep learning research in spectroscopy. SpectrumLab integrates three core components: a comprehensive Python library featuring essential data processing and evaluation tools, along with leaderboards; an innovative SpectrumAnnotator module that generates high-quality benchmarks from limited seed data; and SpectrumBench, a multi-layered benchmark suite covering 14 spectroscopic tasks and over 10 spectrum types, featuring spectra curated from over 1.2 million distinct chemical substances. Thorough empirical studies on SpectrumBench with 18 cutting-edge multimodal LLMs reveal critical limitations of current approaches. We hope SpectrumLab will serve as a crucial foundation for future advancements in deep learning-driven spectroscopy.},
  keywords = {Spectroscopy, Artificial Intelligence, Benchmark}
}

@article{Xie2025-et,
  title    = {QCBench: Evaluating large language models on domain-specific
              Quantitative Chemistry},
  author   = {Jiaqing Xie and Weida Wang and Ben Gao and Zhuo Yang and Haiyuan Wan and Shufei Zhang and Tianfan Fu and Yuqiang Li*},
  journal  = {Journal of Chemical Information and Modeling},
  year     = {2025},
  month    = {nov},
  volume   = {65},
  number   = {22},
  pages    = {12268â€“12278},
  doi      = {10.1021/acs.jcim.5b01455},
  langid   = {english},
  preview  = {QCBench.jpeg},
  abstract = {Quantitative chemistry is central to modern chemical research,
              yet the ability of large language models (LLMs) to perform its
              rigorous, step-by-step calculations remains underexplored. To
              fill this gap, we propose QCBench, a Quantitative Chemistry
              oriented benchmark comprising 350 computational chemistry
              problems across 7 chemistry subfields, which contains analytical
              chemistry, bio-organic chemistry, general chemistry, inorganic
              chemistry, physical chemistry, polymer chemistry and quantum
              chemistry. To systematically evaluate the mathematical reasoning
              abilities of large language models (LLMs), they are categorized
              into three tiers: easy, medium, and difficult. Each problem,
              rooted in realistic chemical scenarios, is structured to prevent
              heuristic shortcuts and demand explicit numerical reasoning.
              QCBench enables fine-grained diagnosis of computational
              weaknesses, reveals model-specific limitations across difficulty
              levels, and lays the groundwork for future improvements such as
              domain-adaptive fine-tuning or multimodal integration.
              Evaluations on 24 LLMs demonstrate a consistent performance
              degradation with increasing task complexity, highlighting the
              current gap between language fluency and scientific computation
              accuracy.},
  code     = {https://github.com/jiaqingxie/QCBench},
  keywords = {Biochemistry, Chemical Calculations, Computational Modeling, Polymer Chemistry, Quantum Mechanics}
}


@artical{yang2025reasoningboenhancingbayesian,
  selected      = {true},
  title         = {Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs},
  author        = {Zhuo Yang and Daolang Wang and Lingli Ge and Beilun Wang and Tianfan Fu and Yuqiang Li*},
  year          = {2025},
  month         = {may},
  url           = {https://arxiv.org/abs/2505.12833},
  preview       = {ReasoningBO.png},
  archiveprefix = {arXiv},
  langid        = {english},
  abstract      = {Many real-world scientific and industrial applications require the optimization of expensive black-box functions. Bayesian Optimization (BO) provides an effective framework for such problems. However, traditional BO methods are prone to get trapped in local optima and often lack interpretable insights. To address this issue, this paper designs Reasoning BO, a novel framework that leverages reasoning models to guide the sampling process in BO while incorporating multi-agent systems and knowledge graphs for online knowledge accumulation. By integrating the reasoning and contextual understanding capabilities of Large Language Models (LLMs), we can provide strong guidance to enhance the BO process. As the optimization progresses, Reasoning BO provides real-time sampling recommendations along with critical insights grounded in plausible scientific theories, aiding in the discovery of superior solutions within the search space. We systematically evaluate our approach across 10 diverse tasks encompassing synthetic mathematical functions and complex real-world applications. The framework demonstrates its capability to progressively refine sampling strategies through real-time insights and hypothesis evolution, effectively identifying higher-performing regions of the search space for focused exploration. This process highlights the powerful reasoning and context-learning abilities of LLMs in optimization scenarios. For example, in the Direct Arylation task, our method increased the yield to 60.7%, whereas traditional BO achieved only a 25.2% yield. Furthermore, our investigation reveals that smaller LLMs, when fine-tuned through reinforcement learning, can attain comparable performance to their larger counterparts.},
  code          = {https://github.com/little1d/Reasoning-BO},
  keywords      = {Bayesian Optimization, Large Language Models}
}